{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(CNN) with TensorFlow Tutorial"
      ],
      "metadata": {
        "id": "RGEognTJEruz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a CNN?\n",
        "\n",
        "A Convolutional Neural Network (CNN or ConvNet) is a deep learning algorithm specifically designed for any task where object recognition is crucial such as image classification, detection, and segmentation.  Many real-life applications, such as self-driving cars, surveillance cameras, and more, use CNNs.\n",
        "\n",
        "The importance of CNNs\n",
        "\n",
        "These are several reasons why CNNs are important, as highlighted below:\n",
        "\n",
        "Unlike traditional machine learning models like SVM and decision trees that require manual feature extractions, CNNs can perform automatic feature extraction at scale, making them efficient.\n",
        "The convolutions layers make CNNs translation invariant, meaning they can recognize patterns from data and extract features regardless of their position, whether the image is rotated, scaled, or shifted.\n",
        "Multiple pre-trained CNN models such as VGG-16, ResNet50, Inceptionv3, and EfficientNet are proved to have reached state-of-the-art results and can be fine-tuned on news tasks using a relatively small amount of data.\n",
        "CNNs can also be used for non-image classification problems and are not limited to natural language processing, time series analysis, and speech recognition.\n",
        "Architecture of a CNN\n",
        "\n",
        "CNNs’ architecture tries to mimic the structure of neurons in the human visual system composed of multiple layers, where each one is responsible for detecting a specific feature in the data.  As illustrated in the image below, the typical CNN is made of a combination of four main layers:\n",
        "\n",
        "Convolutional layers\n",
        "Rectified Linear Unit (ReLU for short)\n",
        "Pooling layers\n",
        "Fully connected layers\n",
        "Let’s understand how each of these layers works using the following example of classification of the handwritten digit.\n",
        "\n",
        "Architecture of the CNNs applied to digit recognition\n",
        "\n",
        "Convolution layers\n",
        "\n",
        "This is the first building block of a CNN. As the name suggests, the main mathematical task performed is called convolution, which is the application of a sliding window function to a matrix of pixels representing an image. The sliding function applied to the matrix is called kernel or filter, and both can be used interchangeably.\n",
        "\n",
        "In the convolution layer, several filters of equal size are applied, and each filter is used to recognize a specific pattern from the image, such as the curving of the digits, the edges, the whole shape of the digits, and more.\n",
        "\n",
        "Let’s consider this 32x32 grayscale image of a handwritten digit. The values in the matrix are given for illustration purposes.\n",
        "\n",
        "Illustration of the input image and its pixel representation\n",
        "\n",
        "Also, let’s consider the kernel used for the convolution. It is a matrix with a dimension of 3x3. The weights of each element of the kernel is represented in the grid. Zero weights are represented in the black grids and ones in the white grid.\n",
        "\n",
        "Do we have to manually find these weights?\n",
        "\n",
        "In real life, the weights of the kernels are determined during the training process of the neural network.\n",
        "\n",
        "Using these two matrices, we can perform the convolution operation by taking applying the dot product, and work as follows:\n",
        "\n",
        "Apply the kernel matrix from the top-left corner to the right.\n",
        "Perform element-wise multiplication.  \n",
        "Sum the values of the products.\n",
        "The resulting value corresponds to the first value (top-left corner) in the convoluted matrix.\n",
        "Move the kernel down with respect to the size of the sliding window.\n",
        "Repeat from step 1 to 5 until the image matrix is fully covered.\n",
        "The dimension of the convoluted matrix depends on the size of the sliding window. The higher the sliding window, the smaller the dimension.\n",
        "\n",
        "Application of the convolution task using a stride of 1 with 3x3 kernel\n",
        "\n",
        "Another name associated with the kernel in the literature is feature detector because the weights can be fine-tuned to detect specific features in the input image.\n",
        "\n",
        "For instance:\n",
        "\n",
        "Averaging neighboring pixels kernel can be used to blur the input image.\n",
        "Subtracting neighboring kernel is used to perform edge detection.\n",
        "The more convolution layers the network has, the better the layer is at detecting more abstract features.\n",
        "\n",
        "Activation function\n",
        "\n",
        "A ReLU activation function is applied after each convolution operation. This function helps the network learn non-linear relationships between the features in the image, hence making the network more robust for identifying different patterns. It also helps to mitigate the vanishing gradient problems.\n",
        "\n",
        "Pooling layer\n",
        "\n",
        "The goal of the pooling layer is to pull the most significant features from the convoluted matrix. This is done by  applying some aggregation operations, which reduces the dimension of the feature map (convoluted matrix), hence reducing the memory used while training the network.  Pooling is also relevant for mitigating overfitting.\n",
        "\n",
        "The most common aggregation functions that can be applied are:\n",
        "\n",
        "Max pooling which is the maximum value of the feature map\n",
        "Sum pooling corresponds to the sum of all the values of the feature map\n",
        "Average pooling is the average of all the values.\n",
        "Below is an illustration of each of the previous example:\n",
        "\n",
        "Application of max pooling with a stride of 2 using 2x2 filter\n",
        "\n",
        "Also, the dimension of the feature map becomes smaller as the polling function is applied.\n",
        "\n",
        "The last pooling layer flattens its feature map so that it can be processed by the fully connected layer.\n",
        "\n",
        "Fully connected layers\n",
        "\n",
        "These layers are in the last layer of the convolutional neural network,  and  their inputs correspond to the flattened one-dimensional matrix generated by the last pooling layer. ReLU activations functions are applied to them for non-linearity.\n",
        "\n",
        "Finally, a softmax prediction layer is used to generate probability values for each of the possible output labels, and the final label predicted is the one with the highest probability score.\n",
        "\n",
        "Dropout\n",
        "\n",
        "Dropout is a regularization technic applied to improve the generalization capability of the neural networks with a large number of parameters. It consists of randomly dropping some neurons during the training process, which forces the remaining neurons to learn new features from the input data.  \n",
        "\n",
        "Since the technical implementation will be performed using TensorFlow 2, the next section aims to provide a complete overview of different components of this framework to efficiently build deep learning models.\n",
        "\n",
        "What is the TensorFlow Framework?\n",
        "\n",
        "Google developed TensorFlow in November 2015. They define it to be an open-source machine learning framework for everyone for several reasons.\n",
        "\n",
        "Definition of Tensorflow\n",
        "\n",
        "Open-source: released under the Apache 2.0 open-source license. This allows researchers, organizations, and developers to make their contribution to the library by building upon it without any restrictions.\n",
        "Machine learning framework: meaning that it has a set of libraries and tools that support the building process of machine learning models.\n",
        "For everyone: Using TensorFlow makes the implementation of machine learning models easier through common programming languages like Python. Furthermore, built-in libraries such as Keras make it even easier to create robust deep learning models.\n",
        "All these functionalities make Tensorflow a good candidate for building neural networks.\n",
        "\n",
        "Furthermore, installing Tensorflow 2 is straightforward and can be performed as follows using the Python package manager pip as explained in the official documentation.\n",
        "\n",
        "After the installation, we can see that the version being used is the 2.9.1"
      ],
      "metadata": {
        "id": "uuR8bOvtEs5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "bva8wOWUE13T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are Tensors?\n",
        "\n",
        "We mainly deal with high-dimensional data when building machine learning and deep learning models. Tensors are multi-dimensional arrays with a uniform type used to represent different features of the data."
      ],
      "metadata": {
        "id": "vdfJXvPmE5IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q-9EDYCPFAmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A 0-dimensional tensor contains a single value.\n",
        "A 1-dimensional tensor, also known as “rank-1” tensor is list of values.\n",
        "A 2-dimensional tensor is a “rank-2” tensor.\n",
        "Finally, we can have a N-dimensional tensor, where N represents the number of dimensions within the tensor. In the previous cases, N is respectively 0, 1 and 2.\n",
        "Below is an illustration of a zero to a 3-dimensional tensor. Each tensor is created using the constant() function from TensorFlow."
      ],
      "metadata": {
        "id": "4RH_-3ifFAoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero dimensional tensor\n",
        "zero_dim_tensor = tf.constant(20)\n",
        "print(zero_dim_tensor)\n",
        "\n",
        "# One dimensional tensor\n",
        "one_dim_tensor = tf.constant([12, 20, 53, 26, 11, 56])\n",
        "print(one_dim_tensor)\n",
        "\n",
        "# Two dimensional tensor\n",
        "two_dim_array = [[3, 6, 7, 5],\n",
        "             \t[9, 2, 3, 4],\n",
        "             \t[7, 1, 10,6],\n",
        "             \t[0, 8, 11,2]]\n",
        "\n",
        "two_dim_tensor = tf.constant(two_dim_array)\n",
        "print(two_dim_tensor)"
      ],
      "metadata": {
        "id": "okRq3SRSFBX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cf10.load_data()"
      ],
      "metadata": {
        "id": "YXxQMMEnFKr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_images(train_images,\n",
        "            \tclass_names,\n",
        "            \ttrain_labels,\n",
        "            \tnb_samples = 12, nb_row = 4):\n",
        "\n",
        "\tplt.figure(figsize=(12, 12))\n",
        "\tfor i in range(nb_samples):\n",
        "    \tplt.subplot(nb_row, nb_row, i + 1)\n",
        "    \tplt.xticks([])\n",
        "    \tplt.yticks([])\n",
        "    \tplt.grid(False)\n",
        "    \tplt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    \tplt.xlabel(class_names[train_labels[i][0]])\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "U4lK-XEDFLZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           \t'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "show_images(train_images, class_names, train_labels)"
      ],
      "metadata": {
        "id": "rmNa2agkFMy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pixel_value = 255\n",
        "\n",
        "train_images = train_images / max_pixel_value\n",
        "test_images = test_images / max_pixel_value"
      ],
      "metadata": {
        "id": "GF9HR0szFOWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels, len(class_names))\n",
        "test_labels = to_categorical(test_labels, len(class_names))"
      ],
      "metadata": {
        "id": "3pzMe0WzFQfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture implementation\n",
        "\n",
        "The next step is to implement the architecture of the network based on the previous description.\n",
        "\n",
        "First, we define the model using the Sequential() class, and each layer is added to the model with the add() function."
      ],
      "metadata": {
        "id": "YU3Fm28BFTXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Variables\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "FILTER1_SIZE = 32\n",
        "FILTER2_SIZE = 64\n",
        "FILTER_SHAPE = (3, 3)\n",
        "POOL_SHAPE = (2, 2)\n",
        "FULLY_CONNECT_NUM = 128\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "# Model architecture implementation\n",
        "model = Sequential()\n",
        "model.add(Conv2D(FILTER1_SIZE, FILTER_SHAPE, activation='relu', input_shape=INPUT_SHAPE))\n",
        "model.add(MaxPooling2D(POOL_SHAPE))\n",
        "model.add(Conv2D(FILTER2_SIZE, FILTER_SHAPE, activation='relu'))\n",
        "model.add(MaxPooling2D(POOL_SHAPE))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(FULLY_CONNECT_NUM, activation='relu'))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "metadata": {
        "id": "sbIIlOCmFXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "\n",
        "METRICS = metrics=['accuracy',\n",
        "               \tPrecision(name='precision'),\n",
        "               \tRecall(name='recall')]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "          \tloss='categorical_crossentropy',\n",
        "          \tmetrics = METRICS)\n",
        "\n",
        "# Train the model\n",
        "training_history = model.fit(train_images, train_labels,\n",
        "                \tepochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                \tvalidation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "q5-4brMDFYWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_performance_curve(training_result, metric, metric_label):\n",
        "\n",
        "\ttrain_perf = training_result.history[str(metric)]\n",
        "\tvalidation_perf = training_result.history['val_'+str(metric)]\n",
        "\tintersection_idx = np.argwhere(np.isclose(train_perf,\n",
        "                                            \tvalidation_perf, atol=1e-2)).flatten()[0]\n",
        "\tintersection_value = train_perf[intersection_idx]\n",
        "\n",
        "\tplt.plot(train_perf, label=metric_label)\n",
        "\tplt.plot(validation_perf, label = 'val_'+str(metric))\n",
        "\tplt.axvline(x=intersection_idx, color='r', linestyle='--', label='Intersection')\n",
        "\n",
        "\tplt.annotate(f'Optimal Value: {intersection_value:.4f}',\n",
        "         \txy=(intersection_idx, intersection_value),\n",
        "         \txycoords='data',\n",
        "         \tfontsize=10,\n",
        "         \tcolor='green')\n",
        "\n",
        "\tplt.xlabel('Epoch')\n",
        "\tplt.ylabel(metric_label)\n",
        "\tplt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "nYZ157-ZFay0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_performance_curve(training_history, 'accuracy', 'accuracy')"
      ],
      "metadata": {
        "id": "JjWBZfJJFcaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_performance_curve(training_history, 'precision', 'precision')"
      ],
      "metadata": {
        "id": "OmQDHAO1Fd4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "test_predictions = model.predict(test_images)\n",
        "\n",
        "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "test_true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "cm = confusion_matrix(test_true_labels, test_predicted_labels)\n",
        "\n",
        "cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "cmd.plot(include_values=True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AF-78RjXFfT7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}